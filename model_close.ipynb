{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia-smi\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivy8792/anaconda3/envs/graph/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from utils.create_data_for_close import get_graph_from_svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "svg_folder = './datasets/svg'\n",
    "png_folder = './datasets/png'\n",
    "imgs = []\n",
    "png = []\n",
    "dataset = []\n",
    "\n",
    "for root, folders, files in os.walk(svg_folder):\n",
    "    for file in files:\n",
    "        if file.split('.')[1] != 'svg': continue\n",
    "        if 'checkpoint' in file: continue\n",
    "        \n",
    "        file_path = os.path.join(svg_folder, file)\n",
    "        imgs.append(file_path)\n",
    "        \n",
    "        file_path = os.path.join(png_folder, file.replace('svg', 'png'))\n",
    "        png.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5440 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i, file_path \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(imgs)):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# try:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39m#     dataset.append(get_graph_from_svg(file_path))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m# except:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m#     print(file_path)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./datasets/svg/042-tree.svg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     get_graph_from_svg(file_path)\n\u001b[1;32m     10\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/graph/utils/create_data_for_close.py:9\u001b[0m, in \u001b[0;36mget_graph_from_svg\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_graph_from_svg\u001b[39m(file_path):\n\u001b[1;32m      8\u001b[0m     G_close, edge_type \u001b[39m=\u001b[39m build_graph(file_path)\n\u001b[0;32m----> 9\u001b[0m     data \u001b[39m=\u001b[39m create_pyg_data(G_close, edge_type)\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/graph/utils/create_data_for_close.py:48\u001b[0m, in \u001b[0;36mcreate_pyg_data\u001b[0;34m(G_close, edge_type)\u001b[0m\n\u001b[1;32m     46\u001b[0m     f \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m G_close\u001b[39m.\u001b[39mnodes[i][\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mv\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     47\u001b[0m     f \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m G_close\u001b[39m.\u001b[39mnodes[i][\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39me\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> 48\u001b[0m     x[i, :] \u001b[39m=\u001b[39m f\n\u001b[1;32m     50\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(x)\n\u001b[1;32m     51\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(y)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 1."
     ]
    }
   ],
   "source": [
    "# 6m 14s\n",
    "for i, file_path in enumerate(tqdm(imgs)):\n",
    "    # try:\n",
    "    #     dataset.append(get_graph_from_svg(file_path))\n",
    "    # except:\n",
    "    #     print(file_path)\n",
    "        \n",
    "    file_path = \"./datasets/svg/042-tree.svg\"\n",
    "    get_graph_from_svg(file_path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 5], edge_index=[2, 26], edge_attr=[26, 1], y=[5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 4624\n",
      "Validation Data: 544\n",
      "Testing Data: 272\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "torch.manual_seed(16)\n",
    "\n",
    "batch_size = 16\n",
    "num_features = 5  # (R, G, B, x, y)\n",
    "num_output = 3  # (R, G, B)\n",
    "num_epoch = 500\n",
    "\n",
    "_train = int(len(dataset) * 0.85)\n",
    "_val = _train + int(len(dataset) * 0.1)\n",
    "_test = len(dataset) - _val\n",
    "\n",
    "# create dataloader\n",
    "train_set, val_set, test_set = dataset[:_train], dataset[_train:_val], dataset[_val:]\n",
    "train_svg, val_svg, test_svg = imgs[:_train], imgs[_train:_val], imgs[_val:]\n",
    "train_png, val_png, test_png = png[:_train], png[_train:_val], png[_val:]\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training Data: {len(train_set)}\\nValidation Data: {len(val_set)}\\nTesting Data: {len(test_set)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_output)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:01<00:00, 235.23it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 455.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTraining Loss: 0.5904875048097855\tValidation Loss: 0.39589134384604063\n",
      "Validation Loss Decreased(inf--->0.395891)\tSaving The Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:00<00:00, 329.85it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 466.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\tTraining Loss: 0.42965951788796686\tValidation Loss: 0.4004649414735682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(2):  # num_epoch\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)  # out.cpu().detach().numpy().shape = (num_node, 3)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    for i, data in enumerate(tqdm(val_loader)):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    train_avg = train_loss / len(train_loader)\n",
    "    val_avg = val_loss / len(val_loader)\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    print(f'Epoch {epoch}\\tTraining Loss: {train_avg}\\tValidation Loss: {val_avg}')\n",
    "    \n",
    "    if val_avg < best_loss:\n",
    "        print(f'Validation Loss Decreased({best_loss:.6f}--->{val_avg:.6f})\\tSaving The Model')\n",
    "        best_loss = val_avg\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "_x = list(range(num_epoch))\n",
    "plt.plot(_x, train_losses, label='Training Loss')\n",
    "plt.plot(_x, val_losses, label='Validation Loss')\n",
    " \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model.load_state_dict(torch.load('./best_checkpoint.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "for i, data in enumerate(tqdm(test_loader)):\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    test_loss += loss.item()\n",
    "    \n",
    "print(f'Testing Loss: {test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize testing results\n",
    "vis_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_state_dict(torch.load('./best_checkpoint.pth'))\n",
    "model.eval()\n",
    "\n",
    "for data, png in zip(vis_loader, test_png):\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    \n",
    "    pos = data.x.cpu().detach().numpy()[:,3:]\n",
    "    rgb = out.cpu().detach().numpy()\n",
    "    \n",
    "    # get pos and hex color\n",
    "    n_rgb = rgb * 255\n",
    "    cc = []\n",
    "    for r, g, b in n_rgb:\n",
    "        cc.append(\"#\" + ('{:X}{:X}{:X}').format(int(r), int(g), int(b)))\n",
    "    \n",
    "    # plot output color\n",
    "    plt.subplot(121)\n",
    "    img = Image.open(png)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    # plt.axis([0, 25, 33, -8])\n",
    "    for (x, y), c in zip(pos, cc):\n",
    "        plt.scatter(x, y, c=c)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88b63015c5eba373d6c9134bd1ac20e0ba3065df798065aa259a5f4513c83141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
