{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQi9cWiKCttl"
      },
      "source": [
        "# **Deep Learning on 3DÂ Meshes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nvidia-smi\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fyqne3fekGyG"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "from pathlib import Path\n",
        "from itertools import tee\n",
        "from functools import lru_cache\n",
        "\n",
        "# import trimesh\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
        "from torch_geometric.transforms import BaseTransform, Compose, FaceToEdge\n",
        "from torch_geometric.data import Data, InMemoryDataset, extract_zip, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "from torch_scatter import scatter\n",
        "from torch_geometric.loader import DataLoader\n",
        "from utils.preprocessing_for_tri_mesh import create_data\n",
        "from utils.preprocessing_for_mesh import create_mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JcrrNbKBHyj"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load image file paths\n",
        "svg_folder = './datasets/svg'\n",
        "png_folder = './datasets/png'\n",
        "imgs = []\n",
        "png = []\n",
        "dataset = []\n",
        "\n",
        "for root, folders, files in os.walk(svg_folder):\n",
        "    for file in files:\n",
        "        if file.split('.')[1] != 'svg': continue\n",
        "        if 'checkpoint' in file: continue\n",
        "        \n",
        "        file_path = os.path.join(svg_folder, file)\n",
        "        imgs.append(file_path)\n",
        "        \n",
        "        file_path = os.path.join(png_folder, file.replace('svg', 'png'))\n",
        "        png.append(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i, file_path in enumerate(tqdm(imgs)):\n",
        "#     # try:\n",
        "#     #     dataset.append(create_mesh(file_path))\n",
        "#     # except:\n",
        "#     #     print(file_path) \n",
        "        \n",
        "#     file_path = \"./datasets/svg/032-firewood.svg\"\n",
        "#     data = create_mesh(file_path)\n",
        "#     print(data)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs = imgs[:2000]\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "dataset = []\n",
        "for data in tqdm(multiprocessing.Pool(8).imap_unordered(create_mesh, imgs), total=len(imgs)):\n",
        "    dataset.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data: 41\n",
            "Validation Data: 5\n",
            "Testing Data: 6\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "torch.manual_seed(16)\n",
        "\n",
        "batch_size = 1\n",
        "num_features = 2  # (x, y)\n",
        "num_output = 1  # (R, G, B) or h\n",
        "num_epoch = 50\n",
        "\n",
        "_train = int(len(dataset) * 0.8)\n",
        "_val = _train + int(len(dataset) * 0.1)\n",
        "_test = len(dataset) - _val\n",
        "\n",
        "# create dataloader\n",
        "train_set, val_set, test_set = dataset[:_train], dataset[_train:_val], dataset[_val:]\n",
        "train_svg, val_svg, test_svg = imgs[:_train], imgs[_train:_val], imgs[_val:]\n",
        "train_png, val_png, test_png = png[:_train], png[_train:_val], png[_val:]\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training Data: {len(train_set)}\\nValidation Data: {len(val_set)}\\nTesting Data: {len(test_set)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmQFG-sEOmGc"
      },
      "source": [
        "# Dataset Defintion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gzKPu4DEkTuG"
      },
      "outputs": [],
      "source": [
        "class NormalizeUnitSphere(BaseTransform):\n",
        "\n",
        "    @staticmethod\n",
        "    def _re_center(x):\n",
        "        centroid = torch.mean(x, dim=0)\n",
        "        return x - centroid\n",
        "\n",
        "    @staticmethod\n",
        "    def _re_scale_to_unit_length(x):\n",
        "        max_dist = torch.max(torch.norm(x, dim=1))\n",
        "        return x / max_dist\n",
        "\n",
        "    def __call__(self, data: Data):\n",
        "        if data.x is not None:\n",
        "            data.x = self._re_scale_to_unit_length(self._re_center(data.x))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"{}()\".format(self.__class__.__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FsbC8UyJspov"
      },
      "outputs": [],
      "source": [
        "def pairwise(iterable):\n",
        "    a, b = tee(iterable)\n",
        "    next(b, None)\n",
        "    return zip(a, b)\n",
        "\n",
        "def get_conv_layers(channels: list, conv: MessagePassing, conv_params: dict):\n",
        "    conv_layers = [\n",
        "        conv(in_ch, out_ch, **conv_params) for in_ch, out_ch in pairwise(channels)\n",
        "    ]\n",
        "    return conv_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vV4G432eAJ2s"
      },
      "outputs": [],
      "source": [
        "def get_mlp_layers(channels: list, activation, output_activation=nn.Identity):\n",
        "    layers = []\n",
        "    *intermediate_layer_definitions, final_layer_definition = pairwise(channels)\n",
        "\n",
        "    for in_ch, out_ch in intermediate_layer_definitions:\n",
        "        intermediate_layer = nn.Linear(in_ch, out_ch)\n",
        "        layers += [intermediate_layer, activation()]\n",
        "\n",
        "    layers += [nn.Linear(*final_layer_definition), output_activation()]\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s_vWPdepsu6b"
      },
      "outputs": [],
      "source": [
        "class FeatureSteeredConvolution(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        num_heads: int,\n",
        "        ensure_trans_invar: bool = True,\n",
        "        bias: bool = True,\n",
        "        with_self_loops: bool = True,\n",
        "    ):\n",
        "        super().__init__(aggr=\"mean\")\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_heads = num_heads\n",
        "        self.with_self_loops = with_self_loops\n",
        "\n",
        "        self.linear = torch.nn.Linear(\n",
        "            in_features=in_channels,\n",
        "            out_features=out_channels * num_heads,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.u = torch.nn.Linear(\n",
        "            in_features=in_channels,\n",
        "            out_features=num_heads,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.c = torch.nn.Parameter(torch.Tensor(num_heads))\n",
        "\n",
        "        if not ensure_trans_invar:\n",
        "            self.v = torch.nn.Linear(\n",
        "                in_features=in_channels,\n",
        "                out_features=num_heads,\n",
        "                bias=False,\n",
        "            )\n",
        "        else:\n",
        "            self.register_parameter(\"v\", None)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.uniform_(self.linear.weight)\n",
        "        torch.nn.init.uniform_(self.u.weight)\n",
        "        torch.nn.init.normal_(self.c, mean=0.0, std=0.1)\n",
        "        if self.bias is not None:\n",
        "            torch.nn.init.normal_(self.bias, mean=0.0, std=0.1)\n",
        "        if self.v is not None:\n",
        "            torch.nn.init.uniform_(self.v.weight)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        if self.with_self_loops:\n",
        "            edge_index, _ = remove_self_loops(edge_index)\n",
        "            edge_index, _ = add_self_loops(edge_index=edge_index, num_nodes=x.shape[0])\n",
        "\n",
        "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
        "        return out if self.bias is None else out + self.bias\n",
        "\n",
        "    def _compute_attention_weights(self, x_i, x_j):\n",
        "        if x_j.shape[-1] != self.in_channels:\n",
        "            raise ValueError(\n",
        "                f\"Expected input features with {self.in_channels} channels.\"\n",
        "                f\" Instead received features with {x_j.shape[-1]} channels.\"\n",
        "            )\n",
        "        if self.v is None:\n",
        "            attention_logits = self.u(x_i - x_j) + self.c\n",
        "        else:\n",
        "            attention_logits = self.u(x_i) + self.b(x_j) + self.c\n",
        "        # return F.relu(attention_logits)\n",
        "        return F.softmax(attention_logits, dim=1)\n",
        "\n",
        "    def message(self, x_i, x_j):\n",
        "        attention_weights = self._compute_attention_weights(x_i, x_j)\n",
        "        x_j = self.linear(x_j).view(-1, self.num_heads, self.out_channels)\n",
        "        return (attention_weights.view(-1, self.num_heads, 1) * x_j).sum(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IKVkmSbjk5dF"
      },
      "outputs": [],
      "source": [
        "class GraphFeatureEncoder(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        conv_channels,\n",
        "        num_heads,\n",
        "        apply_batch_norm: int = True,\n",
        "        ensure_trans_invar: bool = True,\n",
        "        bias: bool = True,\n",
        "        with_self_loops: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        conv_params = dict(\n",
        "            num_heads=num_heads,\n",
        "            ensure_trans_invar=ensure_trans_invar,\n",
        "            bias=bias,\n",
        "            with_self_loops=with_self_loops,\n",
        "        )\n",
        "        self.apply_batch_norm = apply_batch_norm\n",
        "\n",
        "        *first_conv_channels, final_conv_channel = conv_channels\n",
        "        conv_layers = get_conv_layers(\n",
        "            channels=[in_features] + conv_channels,\n",
        "            conv=FeatureSteeredConvolution,\n",
        "            conv_params=conv_params,\n",
        "        )\n",
        "        self.conv_layers = nn.ModuleList(conv_layers)\n",
        "\n",
        "        self.batch_layers = [None for _ in first_conv_channels]\n",
        "        if apply_batch_norm:\n",
        "            self.batch_layers = nn.ModuleList(\n",
        "                [nn.BatchNorm1d(channel) for channel in first_conv_channels]\n",
        "            )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        *first_conv_layers, final_conv_layer = self.conv_layers\n",
        "        for conv_layer, batch_layer in zip(first_conv_layers, self.batch_layers):\n",
        "            x = conv_layer(x, edge_index, edge_attr)\n",
        "            x = F.relu(x)\n",
        "            if batch_layer is not None:\n",
        "                x = batch_layer(x)\n",
        "        return final_conv_layer(x, edge_index, edge_attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9_2-KscKr4c8"
      },
      "outputs": [],
      "source": [
        "class MeshSeg(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        encoder_features,\n",
        "        conv_channels,\n",
        "        encoder_channels,\n",
        "        decoder_channels,\n",
        "        num_classes,\n",
        "        num_heads,\n",
        "        apply_batch_norm=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.input_encoder = get_mlp_layers(\n",
        "            channels=[in_features] + encoder_channels,\n",
        "            activation=nn.ReLU,\n",
        "        )\n",
        "        self.gnn = GraphFeatureEncoder(\n",
        "            in_features=encoder_features,\n",
        "            conv_channels=conv_channels,\n",
        "            num_heads=num_heads,\n",
        "            apply_batch_norm=apply_batch_norm,\n",
        "        )\n",
        "        *_, final_conv_channel = conv_channels\n",
        "\n",
        "        self.final_projection = get_mlp_layers(\n",
        "            [final_conv_channel] + decoder_channels + [num_classes],\n",
        "            activation=nn.ReLU,\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "        x = self.input_encoder(x)\n",
        "        x = self.gnn(x, edge_index, edge_attr)\n",
        "        x = scatter(x, data.cluster, dim=0, reduce='mean')\n",
        "        return self.final_projection(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FYwygTl31zJR"
      },
      "outputs": [],
      "source": [
        "def train(net, train_data, optimizer, loss_fn, device):\n",
        "    net.train()\n",
        "    cumulative_loss = 0.0\n",
        "    err = 0\n",
        "    for i, data in enumerate(train_data):\n",
        "        data = data.to(device)\n",
        "        \n",
        "        if data.x.shape[0] == 0:\n",
        "            err += 1\n",
        "            continue\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        out = net(data)\n",
        "        \n",
        "        # # for hsv\n",
        "        # h = data.h.type(torch.LongTensor).to(device)\n",
        "        # loss = loss_fn(out, h)\n",
        "        \n",
        "        # for rgb\n",
        "        loss = loss_fn(out, data.y)\n",
        "        \n",
        "        # # for rgb w/ scatter\n",
        "        # rgb = scatter(data.y, data.cluster, dim=0, reduce='mean')\n",
        "        # loss = loss_fn(out, rgb)\n",
        "        \n",
        "        loss.backward()\n",
        "        cumulative_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "    return cumulative_loss / (len(train_data)-err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c35Tz1ONtBNa"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(net, train_data, loss_fn, device):\n",
        "    net.eval()\n",
        "    cumulative_loss = 0.0\n",
        "    err = 0\n",
        "    for data in train_data:\n",
        "        data = data.to(device)\n",
        "        if data.x.shape[0] == 0:\n",
        "            err += 1\n",
        "            continue\n",
        "        out = net(data)\n",
        "        \n",
        "        # h = data.h.type(torch.LongTensor).to(device)\n",
        "        # loss = loss_fn(out, h)\n",
        "        \n",
        "        loss = loss_fn(out, data.y)\n",
        "        \n",
        "        # rgb = scatter(data.y, data.cluster, dim=0, reduce='mean')\n",
        "        # loss = loss_fn(out, rgb)\n",
        "        \n",
        "        cumulative_loss += loss.item()\n",
        "    return cumulative_loss / (len(train_data)-err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5WQtyzbaBPej"
      },
      "outputs": [],
      "source": [
        "model_params = dict(\n",
        "    in_features=2,\n",
        "    encoder_features=16,\n",
        "    conv_channels=[32, 64, 128, 64],\n",
        "    encoder_channels=[16],\n",
        "    decoder_channels=[32],\n",
        "    num_classes=3,\n",
        "    num_heads=12,\n",
        "    apply_batch_norm=True,\n",
        ")\n",
        "\n",
        "net = MeshSeg(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MeshSeg(\n",
            "  (input_encoder): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
            "    (1): Identity()\n",
            "  )\n",
            "  (gnn): GraphFeatureEncoder(\n",
            "    (conv_layers): ModuleList(\n",
            "      (0): FeatureSteeredConvolution(16, 32)\n",
            "      (1): FeatureSteeredConvolution(32, 64)\n",
            "      (2): FeatureSteeredConvolution(64, 128)\n",
            "      (3): FeatureSteeredConvolution(128, 64)\n",
            "    )\n",
            "    (batch_layers): ModuleList(\n",
            "      (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (final_projection): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
            "    (3): Identity()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIMlUR_6Br0V"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "num_epochs = 50\n",
        "best_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "# loss_fn = torch.nn.CrossEntropyLoss()\n",
        "loss_fn = torch.nn.MSELoss(reduction='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nfXNyI_BJ9A",
        "outputId": "29e5e652-7540-45af-8469-9e9472bb5c8a"
      },
      "outputs": [],
      "source": [
        "with tqdm(range(num_epochs), unit=\"Epoch\") as tepochs:\n",
        "    for epoch in tepochs:\n",
        "        train_loss = train(net, train_loader, optimizer, loss_fn, device)\n",
        "        val_loss = test(net, val_loader, loss_fn, device)\n",
        "        # train_acc, test_acc = test(net, train_loader, val_loader, device)\n",
        "        \n",
        "        tepochs.set_postfix(\n",
        "            train_loss=train_loss,\n",
        "            val_loss=val_loss,\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        sleep(0.1)\n",
        "        \n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(net.state_dict(), \"seg_ckpt.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_x = list(range(len(train_losses)))\n",
        "plt.plot(_x, train_losses, label='Training Loss')\n",
        "plt.plot(_x, val_losses, label='Validation Loss')\n",
        " \n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize testing results\n",
        "import colorsys\n",
        "\n",
        "vis_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
        "\n",
        "net.load_state_dict(torch.load('./seg_ckpt.pth'))\n",
        "net.eval()\n",
        "\n",
        "for data in vis_loader:\n",
        "    data = data.to(device)\n",
        "    out = net(data)\n",
        "    pos = data.x.cpu().detach().numpy()[:,:2]\n",
        "    H = out.cpu().detach().numpy()\n",
        "    \n",
        "    # # for rgb w/ scatter\n",
        "    # cluster = data.cluster.cpu().detach().numpy()\n",
        "    # for (x, y), clu in zip(pos, cluster):\n",
        "    #     plt.scatter(x, y, color=H[clu])\n",
        "    \n",
        "    # for rgb w/o scatter\n",
        "    for (x, y), (r, g, b) in zip(pos, H):\n",
        "        plt.scatter(x, y, color=[r, g, b])\n",
        "    \n",
        "    # # get pos and hex color\n",
        "    # cc = []\n",
        "    # for h in H:\n",
        "    #     if h[0] == 0: hh = 30 / 360\n",
        "    #     elif h[0] == 1: hh = 60 / 360\n",
        "    #     elif h[0] == 2: hh = 90 / 360\n",
        "    #     elif h[0] == 3: hh = 120 / 360\n",
        "    #     elif h[0] == 4: hh = 150 / 360\n",
        "    #     elif h[0] == 5: hh = 180 / 360\n",
        "    #     elif h[0] == 6: hh = 210 / 360\n",
        "    #     elif h[0] == 7: hh = 240 / 360\n",
        "    #     elif h[0] == 8: hh = 270 / 360\n",
        "    #     elif h[0] == 9: hh = 300 / 360\n",
        "    #     elif h[0] == 10: hh = 330 / 360\n",
        "    #     else: hh = 360 / 360\n",
        "    #     r, g, b = np.array(colorsys.hsv_to_rgb(hh, 1, 1))\n",
        "    #     cc.append([r, g, b])\n",
        "    \n",
        "    # # plt.axis([0, 25, 33, -8])\n",
        "    # for (x, y), c in zip(pos, cc):\n",
        "    #     plt.scatter(x, y, color=c)\n",
        "    \n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "08bd30b9f0ab05f3817be33b04df76a43452a2fb65acc52c317a59d69681516c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
