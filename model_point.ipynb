{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env setting\n",
    "### CUDA version\n",
    "> linux 切換預設連接到的 CUDA 版本\n",
    "1. 查看所有可用的 cuda 版本 `ls -l /usr/local | grep cuda`\n",
    "2. `.bashrc` 增加環境變數\n",
    "    - `export PATH=/usr/local/cuda-11.6/bin:$PATH`\n",
    "    - `export LD_LIBRARY_PATH=/usr/local/cuda-11.6/lib64:$LD_LIBRARY_PATH`\n",
    "3. `source ~/.bashrc` 執行\n",
    "4. cuda version: `nvcc --version`\n",
    "\n",
    "### pytroch and pyg version\n",
    "- [torch version](https://pytorch.org/get-started/previous-versions/)\n",
    "    - `pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116`\n",
    "- [pyg documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)\n",
    "    - `python -c \"import torch; print(torch.__version__)\"` >>> 1.12.1+cu116\n",
    "    - `pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cu116.html`\n",
    "    - `pip install torch-geometric`\n",
    "    - other packages\n",
    "        - `pip install torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-1.12.1+cu116.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia-smi\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from utils.create_data import get_graph_from_svg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. load images\n",
    "2. create pyg data\n",
    "    - [graph data tutorial](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html)\n",
    "    - [dataset tutorial](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html)\n",
    "    - [node classification tutorial](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load images\n",
    "svg_folder = './datasets/svg'\n",
    "png_folder = './datasets/png'\n",
    "imgs = []\n",
    "png = []\n",
    "dataset = []\n",
    "\n",
    "for root, folders, files in os.walk(svg_folder):\n",
    "    for file in files:\n",
    "        if file.split('.')[1] != 'svg': continue\n",
    "        if 'checkpoint' in file: continue\n",
    "        \n",
    "        file_path = os.path.join(svg_folder, file)\n",
    "        imgs.append(file_path)\n",
    "        \n",
    "        file_path = os.path.join(png_folder, file.replace('svg', 'png'))\n",
    "        png.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5440/5440 [19:07<00:00,  4.74it/s]   \n"
     ]
    }
   ],
   "source": [
    "# 19m 7s\n",
    "for i, file_path in enumerate(tqdm(imgs)):\n",
    "    try:\n",
    "        dataset.append(get_graph_from_svg(file_path))\n",
    "    except:\n",
    "        print(file_path)\n",
    "        \n",
    "    # file_path = \"./datasets/svg/036-bookmark.svg\"\n",
    "    # get_graph_from_svg(file_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ThreadPoolExecutor(4) as t:\n",
    "#     graphs = t.map(get_graph_from_svg, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 4624\n",
      "Validation Data: 5168\n",
      "Testing Data: 272\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "torch.manual_seed(16)\n",
    "\n",
    "batch_size = 16\n",
    "num_features = 5  # (R, G, B, x, y)\n",
    "num_output = 3  # (R, G, B)\n",
    "num_epoch = 500\n",
    "\n",
    "_train = int(len(dataset) * 0.85)\n",
    "_val = _train + int(len(dataset) * 0.1)\n",
    "_test = len(dataset) - _val\n",
    "\n",
    "# create dataloader\n",
    "train_set, val_set, test_set = dataset[:_train], dataset[_train:_val], dataset[_val:]\n",
    "train_svg, val_svg, test_svg = imgs[:_train], imgs[_train:_val], imgs[_val:]\n",
    "train_png, val_png, test_png = png[:_train], png[_train:_val], png[_val:]\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training Data: {_train}\\nValidation Data: {_val}\\nTesting Data: {_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_output)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 146/289 [00:05<00:05, 28.01it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.66 GiB (GPU 0; 10.92 GiB total capacity; 7.87 GiB already allocated; 2.44 GiB free; 7.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m out \u001b[39m=\u001b[39m model(data)  \u001b[39m# out.cpu().detach().numpy().shape = (num_node, 3)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, data\u001b[39m.\u001b[39my)\n\u001b[1;32m     17\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m      8\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> 10\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[1;32m     11\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     12\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:198\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    195\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[1;32m    197\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[1;32m    199\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:437\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 437\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    438\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    439\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:207\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mreturn\u001b[39;00m x_j \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m edge_weight\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39;49m x_j\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.66 GiB (GPU 0; 10.92 GiB total capacity; 7.87 GiB already allocated; 2.44 GiB free; 7.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)  # out.cpu().detach().numpy().shape = (num_node, 3)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    for i, data in enumerate(tqdm(val_loader)):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    train_avg = train_loss / len(train_loader)\n",
    "    val_avg = val_loss / len(val_loader)\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    print(f'Epoch {epoch}\\tTraining Loss: {train_avg}\\tValidation Loss: {val_avg}')\n",
    "    \n",
    "    if val_avg < best_loss:\n",
    "        print(f'Validation Loss Decreased({best_loss:.6f}--->{val_avg:.6f})\\tSaving The Model')\n",
    "        best_loss = val_avg\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "_x = list(range(num_epoch))\n",
    "plt.plot(_x, train_losses, label='Training Loss')\n",
    "plt.plot(_x, val_losses, label='Validation Loss')\n",
    " \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model.load_state_dict(torch.load('./best_checkpoint.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "for i, data in enumerate(tqdm(test_loader)):\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    test_loss += loss.item()\n",
    "    \n",
    "print(f'Testing Loss: {test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize testing results\n",
    "vis_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_state_dict(torch.load('./best_checkpoint.pth'))\n",
    "model.eval()\n",
    "\n",
    "for data, png in zip(vis_loader, test_png):\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    \n",
    "    pos = data.x.cpu().detach().numpy()[:,3:]\n",
    "    rgb = out.cpu().detach().numpy()\n",
    "    \n",
    "    # get pos and hex color\n",
    "    n_rgb = rgb * 255\n",
    "    cc = []\n",
    "    for r, g, b in n_rgb:\n",
    "        cc.append(\"#\" + ('{:X}{:X}{:X}').format(int(r), int(g), int(b)))\n",
    "    \n",
    "    # plot output color\n",
    "    plt.subplot(121)\n",
    "    img = Image.open(png)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    # plt.axis([0, 25, 33, -8])\n",
    "    for (x, y), c in zip(pos, cc):\n",
    "        plt.scatter(x, y, c=c)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88b63015c5eba373d6c9134bd1ac20e0ba3065df798065aa259a5f4513c83141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
