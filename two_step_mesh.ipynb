{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install bpy\n",
    "- [參考網站](https://www.zhihu.com/question/386776864)\n",
    "- steps\n",
    "    1. `conda create -n ***`\n",
    "    2. 至 https://pypi.org/project/bpy/#files 查看 python 版本 (cp***)\n",
    "    3. 安裝對應 python 版本 `conda install python=***`\n",
    "    4. `pip install bpy`\n",
    "- (記得切換 kernel -> `conda activate bpy`)\n",
    "## steps and references\n",
    "- preprocessing\n",
    "    - [convert curve to mesh](https://blender.stackexchange.com/questions/265215/how-can-i-convert-a-curve-to-a-mesh-object)\n",
    "    - [get vertices from mesh](https://blender.stackexchange.com/questions/1311/how-can-i-get-vertex-positions-from-a-mesh)\n",
    "    - [get original colors](https://blenderartists.org/t/svg-import-remove-redundant-materials/693325/4)\n",
    "- create mesh\n",
    "    - [triangulate polygon in shapely](https://stackoverflow.com/questions/65019170/how-do-you-triangulate-a-polygon-in-shapely)\n",
    "- simplification\n",
    "    - ~~[tripy](https://github.com/linuxlewis/tripy)~~\n",
    "    - ~~[optimization](https://github.com/meshpro/optimesh)~~\n",
    "    - [triangulate](https://github.com/lionfish0/earclip)\n",
    "## other packages\n",
    "- `pip install scipy`\n",
    "- `pip install shapely`\n",
    "- `pip install geopandas`\n",
    "- `pip install geovoronoi`\n",
    "- `pip install tripy`\n",
    "- `pip install optimesh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bpy\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.wkt\n",
    "import geopandas as gpd\n",
    "import tripy\n",
    "import optimesh\n",
    "import torch\n",
    "import colorsys\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import triangulate\n",
    "from matplotlib.lines import Line2D\n",
    "from geovoronoi import voronoi_regions_from_coords\n",
    "from quad_mesh_simplify import simplify_mesh\n",
    "from collections import OrderedDict\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FINISHED'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import file\n",
    "file_path = \"./datasets/svg/011-library.svg\"\n",
    "# file_path = \"./datasets/svg/037-time.svg\"\n",
    "# file_path = \"./datasets/svg/027-diamond.svg\"\n",
    "# file_path = \"./datasets/svg/019-watermelon.svg\"\n",
    "# file_path = \"./datasets/svg/024-book.svg\"\n",
    "# file_path = \"./datasets/svg/032-firewood.svg\"\n",
    "# file_path = \"./datasets/svg/050-shopping cart.svg\"\n",
    "\n",
    "# clean the scene\n",
    "bpy.ops.object.select_all()\n",
    "bpy.ops.object.delete()\n",
    "bpy.ops.import_curve.svg(filepath=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert curve to mesh\n",
    "idx = 0\n",
    "for ob in bpy.data.objects:\n",
    "    if ob.type == \"CURVE\":\n",
    "        mesh = bpy.data.meshes.new_from_object(ob)\n",
    "        new_obj = bpy.data.objects.new(\"mesh_obj\" + str(idx), mesh)\n",
    "        new_obj.matrix_world = ob.matrix_world\n",
    "        bpy.context.collection.objects.link(new_obj)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all curve meshes\n",
    "colors = {}\n",
    "nodes = {}\n",
    "idx = 0\n",
    "hsv = {}\n",
    "for ob in bpy.data.objects:\n",
    "    if ob.type == \"MESH\" and \"mesh_obj\" in ob.name:\n",
    "        try:\n",
    "            # get mesh\n",
    "            rgb = ob.material_slots[0].material.diffuse_color\n",
    "            colors[idx] = np.array([rgb[0], rgb[1], rgb[2]])\n",
    "            hsv[idx] = np.array(colorsys.rgb_to_hsv(rgb[0], rgb[1], rgb[2]))\n",
    "            \n",
    "            # get vertices\n",
    "            v = ob.data.vertices[0]\n",
    "            coords = [(ob.matrix_world @ v.co) for v in ob.data.vertices]  # (x, y, z)\n",
    "            nodes[idx] = []\n",
    "            for x, y, z in coords:\n",
    "                nodes[idx].append([x, y]) \n",
    "            nodes[idx] = np.array(nodes[idx])\n",
    "            \n",
    "            idx += 1\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangulate\n",
    "from shapely.ops import triangulate\n",
    "\n",
    "polys = {}\n",
    "all_polys = []\n",
    "for i, node in nodes.items():\n",
    "    polys[i] = []\n",
    "    all_polys.append(None)\n",
    "    if len(node) < 4: continue\n",
    "    \n",
    "    poly = Polygon(node).buffer(0.001)\n",
    "    all_polys[i] = poly\n",
    "    tri = triangulate(poly)\n",
    "    for po in tri:\n",
    "        xx, yy = po.exterior.coords.xy\n",
    "        temp = []\n",
    "        for x, y in zip(xx, yy):\n",
    "            temp.append([x, y])\n",
    "        polys[i].append(temp[:3])\n",
    "    polys[i] = np.array(polys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first stage\n",
    "all_points = []\n",
    "all_edges = []\n",
    "all_rgb = []\n",
    "all_hsv = []\n",
    "all_cluster = []\n",
    "add_num = 0\n",
    "new_polys = []\n",
    "idx = 0\n",
    "\n",
    "for i, poly in polys.items():\n",
    "    if len(poly) == 0: continue\n",
    "    new_polys.append(all_polys[i])\n",
    "    \n",
    "    p_i = 0\n",
    "    pos2idx = {}\n",
    "    points = []\n",
    "    cells = []\n",
    "    for n1, n2, n3 in poly:\n",
    "        if tuple(n1) not in pos2idx:\n",
    "            pos2idx[tuple(n1)] = p_i\n",
    "            points.append(n1)\n",
    "            all_rgb += [colors[i].tolist()]\n",
    "            all_hsv += [hsv[i].tolist()]\n",
    "            p_i += 1\n",
    "        if tuple(n2) not in pos2idx:\n",
    "            pos2idx[tuple(n2)] = p_i\n",
    "            points.append(n2)\n",
    "            all_rgb += [colors[i].tolist()]\n",
    "            all_hsv += [hsv[i].tolist()]\n",
    "            p_i += 1\n",
    "        if tuple(n3) not in pos2idx:\n",
    "            pos2idx[tuple(n3)] = p_i\n",
    "            points.append(n3)\n",
    "            all_rgb += [colors[i].tolist()]\n",
    "            all_hsv += [hsv[i].tolist()]\n",
    "            p_i += 1       \n",
    "        cells.append([pos2idx[tuple(n1)], pos2idx[tuple(n2)], pos2idx[tuple(n3)]])\n",
    "        \n",
    "    points = np.array(points)\n",
    "    cells = np.array(cells) \n",
    "    points, cells = optimesh.optimize_points_cells(\n",
    "        points, cells, \"cpt-quasi-newton\", 1.0e-5, 100\n",
    "    )\n",
    "    \n",
    "    if idx == 0:\n",
    "        all_points = points\n",
    "    else:\n",
    "        all_points = np.concatenate((all_points, points), axis=0)\n",
    "    for a, b, c in cells:\n",
    "        all_edges.append([a+add_num, b+add_num])\n",
    "        all_edges.append([b+add_num, c+add_num])\n",
    "        all_edges.append([c+add_num, a+add_num])\n",
    "    add_num += len(points)\n",
    "    \n",
    "    all_cluster += [idx for _ in range(len(points))]\n",
    "    idx += 1\n",
    "    \n",
    "all_points = np.array(all_points)\n",
    "all_edges = np.array(all_edges)\n",
    "all_rgb = np.array(all_rgb)\n",
    "all_hsv = np.array(all_hsv)\n",
    "all_cluster = np.array(all_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all points: 3752\n",
      "number of all edges: 15780\n",
      "rgb: (3752, 3); hsv: (3752, 3); cluster: (3752,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of all points: {len(all_points)}\")\n",
    "print(f\"number of all edges: {len(all_edges)}\")\n",
    "print(f\"rgb: {all_rgb.shape}; hsv: {all_hsv.shape}; cluster: {all_cluster.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overlap\n",
    "def block_intersect(i, j, poly1, poly2, group_edges, group_edges_type):\n",
    "    a1 = poly1.area\n",
    "    a2 = poly2.area\n",
    "    intersect = poly1.intersection(poly2).area\n",
    "    \n",
    "    if abs(intersect - min(a1, a2)) < 0.000001:  # in\n",
    "        group_edges.append([i, j])\n",
    "        group_edges.append([j, i])\n",
    "        group_edges_type.append(2)\n",
    "        group_edges_type.append(2)\n",
    "    elif intersect != 0:  # overlap\n",
    "        group_edges.append([i, j])\n",
    "        group_edges.append([j, i])\n",
    "        group_edges_type.append(1)\n",
    "        group_edges_type.append(1)\n",
    "    else:  # adjacent\n",
    "        group_edges.append([i, j])\n",
    "        group_edges.append([j, i])\n",
    "        group_edges_type.append(0)\n",
    "        group_edges_type.append(0)\n",
    "        \n",
    "    return group_edges, group_edges_type\n",
    "\n",
    "# check group connection\n",
    "group_edges = []\n",
    "group_edges_type = []\n",
    "\n",
    "for i in range(len(new_polys)-1):\n",
    "    for j in range(i+1, len(new_polys)):\n",
    "        group_edges, group_edges_type = block_intersect(i, j, new_polys[i], new_polys[j], group_edges, group_edges_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[835, 2], edge_index=[2, 6594], edge_attr=[6594, 4], rgb=[835, 3], hsv=[835, 3], cluster=[835], group_edge_index=[2, 30], group_edge_attr=[30])\n"
     ]
    }
   ],
   "source": [
    "# create pyg data\n",
    "# nodes\n",
    "x = torch.Tensor(all_points)\n",
    "y_rgb = torch.Tensor(all_rgb)\n",
    "y_hsv = torch.Tensor(all_hsv)\n",
    "y_cluster = torch.Tensor(all_cluster)\n",
    "\n",
    "# edges\n",
    "m = all_edges.shape[0]\n",
    "edges = np.zeros([2*m, 2]).astype(np.int64)\n",
    "edge_attr = np.zeros([2*m, 4]).astype(np.float32)\n",
    "for e, (s,t) in enumerate(all_edges):\n",
    "    edges[e, 0] = s\n",
    "    edges[e, 1] = t\n",
    "    edges[m+e, 0] = t\n",
    "    edges[m+e, 1] = s\n",
    "    \n",
    "    edge_attr[e, :2] = all_points[s]\n",
    "    edge_attr[e, 2:] = all_points[t]\n",
    "    edge_attr[m+e, :2] = all_points[t]\n",
    "    edge_attr[m+e, 2:] = all_points[s]\n",
    "edges = torch.Tensor(np.transpose(edges)).type(torch.long)\n",
    "edge_attr = torch.Tensor(edge_attr)\n",
    "\n",
    "group_edges = torch.Tensor(np.transpose(group_edges)).type(torch.long)\n",
    "group_edge_attr = torch.Tensor(group_edges_type)\n",
    "\n",
    "data = Data(x=x, edge_index=edges, rgb=y_rgb, hsv=y_hsv, edge_attr=edge_attr, cluster=y_cluster, group_edge_index=group_edges, group_edge_attr=group_edge_attr)\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 2-stage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn, Tensor\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "torch.manual_seed(16)\n",
    "\n",
    "batch_size = 1\n",
    "num_features = 2\n",
    "num_output = 3\n",
    "num_epoch = 50\n",
    "\n",
    "# _train = int(len(dataset) * 0.9)\n",
    "# _val = _train + int(len(dataset) * 0.05)\n",
    "# _test = len(dataset) - _val\n",
    "\n",
    "# # create dataloader\n",
    "# train_set, val_set, test_set = dataset[:_train], dataset[_train:_val], dataset[_val:]\n",
    "# train_svg, val_svg, test_svg = imgs[:_train], imgs[_train:_val], imgs[_val:]\n",
    "# train_png, val_png, test_png = png[:_train], png[_train:_val], png[_val:]\n",
    "\n",
    "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# print(f\"Training Data: {len(train_set)}\\nValidation Data: {len(val_set)}\\nTesting Data: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(2, 16, improved=True)\n",
    "        self.conv2 = GCNConv(16, 64, improved=True)\n",
    "        \n",
    "    def forward(self, x, edge_index, cluster):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = scatter(x, cluster, dim=0, reduce='mean')\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(64, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "# class SVGConv(MessagePassing):\n",
    "#     def __init__(self,\n",
    "#                  in_channels: int,\n",
    "#                  out_channels: int,\n",
    "#                  improved: bool = True,\n",
    "#                  add_self_loops: bool = True,\n",
    "#                  normalize: bool = True,\n",
    "#                  bias: bool = True,\n",
    "#                  **kwargs\n",
    "#     ):\n",
    "#         super(SVGConv, self).__init__(aggr=\"mean\", **kwargs)\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.improved = improved\n",
    "#         self.add_self_loops = add_self_loops\n",
    "#         self.normalize = normalize\n",
    "        \n",
    "#         self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        \n",
    "#         if bias:\n",
    "#             self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "#         else:\n",
    "#             self.register_parameter(\"bias\", None)\n",
    "        \n",
    "#         self.reset_parameters()\n",
    "        \n",
    "#     def reset_parameters(self):\n",
    "#         torch.nn.init.uniform_(self.lin.weight)\n",
    "#         if self.bias is not None:\n",
    "#             torch.nn.init.normal_(self.bias, mean=0.0, std=0.1)\n",
    "        \n",
    "#     def forward(self, x, edge_index, edge_attr):\n",
    "#         out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "#         return out\n",
    "    \n",
    "#     def message(self, x_i, x_j, edge_attr):\n",
    "#         if edge_attr == 2:  # overlap\n",
    "            \n",
    "#         elif edge_attr == 3:  # contain\n",
    "#         else:  # adjacent\n",
    "            \n",
    "#         return super().message(x_j)\n",
    "    \n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.encode = GraphEncoder()\n",
    "        self.gcn1 = GCNConv(64, 128)\n",
    "        self.gcn2 = GCNConv(128, 64)\n",
    "        # self.gcn1 = SVGConv(64, 128)\n",
    "        # self.gcn2 = SVGConv(128, 64)\n",
    "        self.fc = MLP()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        cluster = data.cluster.type(torch.long)\n",
    "        group_edge_index, group_edge_attr = data.group_edge_index, data.group_edge_attr\n",
    "        \n",
    "        feature = self.encode(x, edge_index, cluster)\n",
    "        \n",
    "        out = self.gcn1(feature, group_edge_index, group_edge_attr)\n",
    "        out = F.relu(out)\n",
    "        out = self.gcn2(out, group_edge_index, group_edge_attr)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.7067, 0.0000],\n",
      "        [0.0000, 0.7067, 0.0000],\n",
      "        [0.0000, 0.7067, 0.0000],\n",
      "        [1.4067, 0.0000, 1.4124],\n",
      "        [1.4067, 0.0000, 1.4124],\n",
      "        [0.0000, 0.7067, 0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.3185, 0.4910, 1.0000],\n",
      "        [0.1301, 0.3185, 0.9911],\n",
      "        [0.8228, 0.7913, 0.8963],\n",
      "        [0.9823, 0.0612, 0.1144],\n",
      "        [0.9823, 0.1500, 0.1144],\n",
      "        [1.0000, 0.9047, 0.9216]], device='cuda:0')\n",
      "0.5238862633705139\n",
      "tensor([[0.6899, 0.0000, 0.6897],\n",
      "        [0.6899, 0.0000, 0.6897],\n",
      "        [0.6899, 0.0000, 0.6897],\n",
      "        [0.0000, 1.3851, 0.0000],\n",
      "        [0.0000, 1.3851, 0.0000],\n",
      "        [0.6899, 0.0000, 0.6897]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.3185, 0.4910, 1.0000],\n",
      "        [0.1301, 0.3185, 0.9911],\n",
      "        [0.8228, 0.7913, 0.8963],\n",
      "        [0.9823, 0.0612, 0.1144],\n",
      "        [0.9823, 0.1500, 0.1144],\n",
      "        [1.0000, 0.9047, 0.9216]], device='cuda:0')\n",
      "0.4372161030769348\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_loss = float('inf')\n",
    "err = 0\n",
    "\n",
    "for epoch in range(2):  # num_epoch\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    data = data.to(device)\n",
    "    if data.x.shape[0] == 0:\n",
    "        err += 1\n",
    "        continue\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    \n",
    "    cluster = data.cluster.type(torch.long)\n",
    "    rgb = scatter(data.rgb, cluster, dim=0, reduce='mean')\n",
    "    loss = criterion(out, rgb)\n",
    "    \n",
    "    print(out)\n",
    "    print(rgb)\n",
    "    print(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# best_loss = float('inf')\n",
    "# err = 0\n",
    "\n",
    "# for epoch in range(2):  # num_epoch\n",
    "#     train_loss = 0\n",
    "#     val_loss = 0\n",
    "    \n",
    "#     model.train()\n",
    "#     for i, data in enumerate(tqdm(train_loader)):\n",
    "#         data = data.to(device)\n",
    "#         if data.x.shape[0] == 0:\n",
    "#             err += 1\n",
    "#             continue\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(data)\n",
    "#         # h = data.h.type(torch.LongTensor).to(device)\n",
    "#         # loss = criterion(out, h)\n",
    "#         loss = criterion(out, data.rgb)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "        \n",
    "#     model.eval()\n",
    "#     for i, data in enumerate(tqdm(val_loader)):\n",
    "#         data = data.to(device)\n",
    "#         out = model(data)\n",
    "        \n",
    "#         # h = data.h.type(torch.LongTensor).to(device)\n",
    "#         # loss = criterion(out, h)\n",
    "#         loss = criterion(out, data.rgb)\n",
    "        \n",
    "#         val_loss += loss.item()\n",
    "    \n",
    "#     train_avg = train_loss / len(train_loader)\n",
    "#     val_avg = val_loss / len(val_loader)\n",
    "#     train_losses.append(loss.item())\n",
    "#     val_losses.append(loss.item())\n",
    "    \n",
    "#     print(f'Epoch {epoch}\\tTraining Loss: {train_avg}\\tValidation Loss: {val_avg}')\n",
    "    \n",
    "#     if val_avg < best_loss:\n",
    "#         print(f'Validation Loss Decreased({best_loss:.6f}--->{val_avg:.6f})\\tSaving The Model')\n",
    "#         best_loss = val_avg\n",
    "#         torch.save(model.state_dict(), 'best_checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08bd30b9f0ab05f3817be33b04df76a43452a2fb65acc52c317a59d69681516c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
