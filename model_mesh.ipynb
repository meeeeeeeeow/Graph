{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia-smi\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from torch.nn import Sequential as Seq, Linear, Parameter, ReLU\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from utils.preprocessing_for_mesh import create_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image file paths\n",
    "svg_folder = './datasets/svg'\n",
    "png_folder = './datasets/png'\n",
    "imgs = []\n",
    "png = []\n",
    "dataset = []\n",
    "\n",
    "for root, folders, files in os.walk(svg_folder):\n",
    "    for file in files:\n",
    "        if file.split('.')[1] != 'svg': continue\n",
    "        if 'checkpoint' in file: continue\n",
    "        \n",
    "        file_path = os.path.join(svg_folder, file)\n",
    "        imgs.append(file_path)\n",
    "        \n",
    "        file_path = os.path.join(png_folder, file.replace('svg', 'png'))\n",
    "        png.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, file_path in enumerate(tqdm(imgs)):\n",
    "#     try:\n",
    "#         dataset.append(create_mesh(file_path))\n",
    "#     except:\n",
    "#         print(file_path) \n",
    "        \n",
    "#     # file_path = \"./datasets/svg/032-firewood.svg\"\n",
    "#     # data = create_mesh(file_path)\n",
    "#     # print(data)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:01<00:00,  8.28it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs = imgs[:2000]\n",
    "dataset = []\n",
    "for data in tqdm(multiprocessing.Pool(8).imap_unordered(create_mesh, imgs), total=len(imgs)):\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 1600\n",
      "Validation Data: 200\n",
      "Testing Data: 200\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "torch.manual_seed(16)\n",
    "\n",
    "batch_size = 32\n",
    "num_features = 2\n",
    "num_output = 1\n",
    "num_epoch = 500\n",
    "\n",
    "_train = int(len(dataset) * 0.8)\n",
    "_val = _train + int(len(dataset) * 0.1)\n",
    "_test = len(dataset) - _val\n",
    "\n",
    "# create dataloader\n",
    "train_set, val_set, test_set = dataset[:_train], dataset[_train:_val], dataset[_val:]\n",
    "train_svg, val_svg, test_svg = imgs[:_train], imgs[_train:_val], imgs[_val:]\n",
    "train_png, val_png, test_png = png[:_train], png[_train:_val], png[_val:]\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training Data: {len(train_set)}\\nValidation Data: {len(val_set)}\\nTesting Data: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm, edge_attr=edge_attr)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)\n",
    "    \n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channels, in_channels*2),\n",
    "            torch.nn.BatchNorm1d(in_channels*2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_channels*2, out_channels*2),\n",
    "            torch.nn.BatchNorm1d(out_channels*2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels*2, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, num_features*2)\n",
    "        self.conv2 = GCNConv(num_features*2, num_features)\n",
    "        self.mlp = MLP(num_features, 1)\n",
    "        \n",
    "        # self.conv1 = EdgeConv(num_features, 16)\n",
    "        # self.conv2 = EdgeConv(16, num_output)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# criterion = torch.nn.MSELoss(reduction='mean')\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[0;32m---> 12\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m     out \u001b[39m=\u001b[39m model(data)  \u001b[39m# out.cpu().detach().numpy().shape = (num_node, 3)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bpy/lib/python3.10/site-packages/torch_geometric/data/data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m    248\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    252\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/bpy/lib/python3.10/site-packages/torch_geometric/data/data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstores:\n\u001b[0;32m--> 234\u001b[0m     store\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/bpy/lib/python3.10/site-packages/torch_geometric/data/storage.py:163\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m recursive_apply(value, func)\n\u001b[1;32m    164\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/bpy/lib/python3.10/site-packages/torch_geometric/data/storage.py:523\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    522\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 523\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n\u001b[1;32m    524\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mPackedSequence):\n\u001b[1;32m    525\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/bpy/lib/python3.10/site-packages/torch_geometric/data/data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m    248\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\n\u001b[0;32m--> 252\u001b[0m         \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39margs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(2):  # num_epoch\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)  # out.cpu().detach().numpy().shape = (num_node, 3)\n",
    "        h = data.h.type(torch.LongTensor).to(device)\n",
    "        loss = criterion(out, h)\n",
    "        # loss = criterion(out, data.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    for i, data in enumerate(tqdm(val_loader)):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        \n",
    "        h = data.h.type(torch.LongTensor).to(device)\n",
    "        loss = criterion(out, h)\n",
    "        # loss = criterion(out, data.y)\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    train_avg = train_loss / len(train_loader)\n",
    "    val_avg = val_loss / len(val_loader)\n",
    "    train_losses.append(train_avg)\n",
    "    val_losses.append(val_avg)\n",
    "    \n",
    "    print(f'Epoch {epoch}\\tTraining Loss: {train_avg}\\tValidation Loss: {val_avg}')\n",
    "    \n",
    "    if val_avg < best_loss:\n",
    "        print(f'Validation Loss Decreased({best_loss:.6f}--->{val_avg:.6f})\\tSaving The Model')\n",
    "        best_loss = val_avg\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_x = list(range(num_epoch))\n",
    "plt.plot(_x, train_losses, label='Training Loss')\n",
    "plt.plot(_x, val_losses, label='Validation Loss')\n",
    " \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model.load_state_dict(torch.load('./best_checkpoint.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "for i, data in enumerate(tqdm(test_loader)):\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    test_loss += loss.item()\n",
    "    \n",
    "print(f'Testing Loss: {test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize testing results\n",
    "vis_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_state_dict(torch.load('./best_checkpoint.pth'))\n",
    "model.eval()\n",
    "\n",
    "for data, png in zip(vis_loader, test_png):\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    \n",
    "    pos = data.x.cpu().detach().numpy()[:,3:]\n",
    "    rgb = out.cpu().detach().numpy()\n",
    "    \n",
    "    # get pos and hex color\n",
    "    n_rgb = rgb * 255\n",
    "    cc = []\n",
    "    for r, g, b in n_rgb:\n",
    "        cc.append(\"#\" + ('{:X}{:X}{:X}').format(int(r), int(g), int(b)))\n",
    "    \n",
    "    # # plot output color\n",
    "    # plt.subplot(121)\n",
    "    # img = Image.open(png)\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.imshow(img)\n",
    "    \n",
    "    # plt.subplot(122)\n",
    "    # # plt.axis([0, 25, 33, -8])\n",
    "    for (x, y), c in zip(pos, cc):\n",
    "        plt.scatter(x, y, c=c)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08bd30b9f0ab05f3817be33b04df76a43452a2fb65acc52c317a59d69681516c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
